\documentclass{beamer}
\usetheme{Warsaw}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{fancybox}
\usepackage{multimedia} 
\usepackage{subfig}
\usepackage{amsmath}

\usepackage[all]{xy}
\begin{document}


\title[Computergrafik] % (optional, only for long titles)
{Computergrafik
}
\subtitle{}
\author[Dr. Johannes Riesterer] % (optional, for multiple authors)
{Dr.  rer. nat. Johannes Riesterer}

\date[KPT 2004] % (optional)
{}

\subject{Computergrafik}



\begin{frame}
    \frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}
    \begin{block}{Grafikprozessor (GPU)}
        Ein Grafikprozessor (Graphics Processing Unit, GPU) ist eine spezialisierte elektronische Schaltung, die entwickelt wurde, um die Berechnung und Darstellung von Bildern und Grafiken auf einem Computerbildschirm zu beschleunigen. 
        GPUs sind besonders gut geeignet für parallele Verarbeitung großer Datenmengen, 
        was sie ideal für  Anwendungen wie Videospiele, 3D-Modellierung und maschinelles Lernen macht.
    \end{block}
\end{frame}
\begin{frame}
    \frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}
    \begin{block}{Leistungsfähigkeit von GPUs}
        Die Leistungsfähigkeit von GPUs wird oft in Teraflops (TFLOPS) gemessen, 
        was die Anzahl der Billionen Gleitkommaoperationen pro Sekunde angibt, 
        die sie ausführen können. Moderne GPUs können je nach Modell und Anwendungsbereich unterschiedliche Leistungsstufen erreichen.
        Typische Rechengenauigkeiten sind 32-Bit (FP32) und 16-Bit (FP16) Gleitkommazahlen.
        Bei 64-Bit (FP64) Gleitkommazahlen ist die Leistung in der Regel deutlich geringer.
    \end{block}
    
\begin{table}[h]
    \centering
    \tiny % Schriftgröße ändern
    \begin{tabular}{|l|l|}
    \hline
    \textbf{GPU-Klasse} & \textbf{Leistung} \\ \hline
    \textbf{Einsteiger- / Mittelklasse} & 2 - 10 TFLOPS \\ \hline
    \textbf{High-End-Gaming} & 10 - 100 TFLOPS \\ \hline
    \textbf{Workstation- / AI-GPUs} & 20 - 1000 TFLOPS \\ \hline
    \end{tabular}
    \end{table}
\vspace{2mm}
\href{https://www.gpu-monkey.com/de/benchmark-nvidia_rtx_6000_ada-fp32}{Quelle: GPU Monkey Benchmark NVIDIA RTX 6000 ADA FP32}\\
\href{https://www.megware.com/fileadmin/user_upload/LandingPage\%20NVIDIA/nvidia-h100-datasheet.pdf}{Quelle: NVIDIA H100 Datasheet}

\end{frame}



\begin{frame}
    \frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}
\begin{columns}[c]
    \column{0.5\textwidth}
    \centering
    \includegraphics[width=0.95\linewidth]{images/gpu3.png}

    \column{0.5\textwidth}
    \centering
    \includegraphics[width=0.95\linewidth]{images/gpu2.png}
\end{columns}
\end{frame}





\begin{frame}{Aufbau und Funktionsweise einer GPU}
\frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}
    \begin{itemize}
      \item \textbf{Architektur:} Viele einfache Rechenkerne in \textit{Streaming Multiprocessors (SM)}, optimiert für parallele Berechnung.
      \item \textbf{Speicherhierarchie:}
      \begin{itemize}
        \item \textit{Global Memory (VRAM)}: Großer, langsamer Speicher für die gesamte GPU.
        \item \textit{Shared Memory}: Schneller Zwischenspeicher pro SM.
        \item \textit{Register}: Klein, extrem schnell, lokal pro Kern.
      \end{itemize}
      \item \textbf{SIMD-Prinzip:} Gleiche Operation auf mehrere Daten gleichzeitig (Single Instruction, Multiple Data).
      \item \textbf{Thread-Modell:} Threads in \textit{Thread-Blocks} organisiert, diese in einem \textit{Grid}.
      \item \textbf{Spezialisierte Hardware:} Rasterisierung, Texturierung und Shading für Grafikoperationen.
    \end{itemize}
  \end{frame}

\begin{frame}{Was ist eine Shader Unit?}
\frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}
\begin{block}{Shader Unit}
\begin{itemize}
    \item Eine \textbf{Shader Unit} ist ein \textbf{ALU-Rechenwerk} (z.\,B. FP32/INT) \textbf{innerhalb eines Streaming Multiprocessors (SM)}.
    \item Ein \textbf{SM} enthält \textbf{viele Shader Units} plus \textbf{Warp/Thread-Scheduler}, \textbf{Register-Datei} und \textbf{Shared Memory}.
    \item Viele SMs zusammen bilden den \textbf{GPU-Rechenteil} (neben festen Grafik-Blöcken wie Rasterizer/Textur-Einheiten).
\end{itemize}
\end{block}
\end{frame}

\begin{frame}
    \frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.35]{images/gpu1.png}
    \caption{\scriptsize Quelle: https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html}
\end{figure}
\end{frame}

% ------------------------------------------------------------
% GPU Programmierung (einfach erklärt)
% ------------------------------------------------------------

\begin{frame}{GPU-Programmierung: Grundidee}
\frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}
\begin{block}{Was macht die GPU schnell?}
Die GPU ist schnell, wenn sie \textbf{sehr viele ähnliche Rechnungen gleichzeitig} machen kann.
\begin{itemize}
  \item Bild: viele Pixel werden parallel berechnet
  \item Geometrie: viele Vertices werden parallel transformiert
  \item KI/Mathe: viele Zahlen in großen Matrizen werden parallel verarbeitet
\end{itemize}
\end{block}

\begin{block}{Was ist wichtig beim Programmieren?}
\begin{itemize}
  \item \textbf{Große Aufgaben auf einmal:} lieber 1 große Rechnung als 1000 kleine
  \item \textbf{Daten nicht ständig hin- und herschieben:} CPU $\leftrightarrow$ GPU kostet Zeit
  \item \textbf{Wenig Verzweigungen:} wenn viele Threads unterschiedliche Wege gehen, wird es langsamer
\end{itemize}
\end{block}
\end{frame}


\begin{frame}{GPU-Programmierung: Wie nutzt man sie?}
\frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}
\begin{block}{Zwei typische Wege}
\begin{itemize}
  \item \textbf{Grafik (Shader):} Programme für Vertex/Pixel in OpenGL/Vulkan/Direct3D/Metal/WebGPU
  \item \textbf{Rechnen (Compute):} GPU als Parallelrechner (Compute Shader oder CUDA/HIP/OpenCL)
\end{itemize}
\end{block}

\begin{block}{PyTorch als "GPU-Programmierung ohne viel API-Aufwand"}
In PyTorch sind viele Tensor-Operationen intern GPU-Kernels.
Man schreibt Code in Python, aber die GPU rechnet die großen Operationen.
\end{block}
\end{frame}



\begin{frame}{CPU-RAM $\rightarrow$ GPU-VRAM: wie lange dauert das grob?}
\frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}
\begin{block}{Grobe Größenordnung}
Die Kopie läuft typischerweise über \textbf{PCI Express (PCIe)}:
\begin{itemize}
  \item \textbf{Große, zusammenhängende Datenblöcke:} typischerweise \textbf{Millisekunden pro 100 MB}
  \item \textbf{Sehr große Transfers (GB-Bereich):} typischerweise \textbf{Zehner-Millisekunden pro GB}
  \item \textbf{Viele kleine Transfers:} oft \textbf{deutlich langsamer}, weil pro Transfer ein fester Overhead anfällt
\end{itemize}
\end{block}

\begin{block}{Warum kleine Kopien besonders schlecht sind}
PCIe ist paketbasiert und jede Kopie hat Overhead. Deshalb:
\textbf{lieber wenige große Kopien statt vieler kleiner.}
\end{block}

\scriptsize
\href{https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/}{Quelle: NVIDIA Blog (Transfers bündeln, pinned memory)}\\
\href{https://forums.developer.nvidia.com/t/question-about-pci-e-transfer-throughput/328759}{Quelle: NVIDIA Forum (realistische PCIe4 x16 Durchsatzwerte, Overhead bei kleinen Transfers)}
\end{frame}


\begin{frame}{Warum das ein Flaschenhals ist}
\frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}
\begin{block}{Das Nadelöhr: PCIe vs. GPU-internes Speichertempo}
\begin{itemize}
  \item PCIe 4.0 x16 liegt grob bei \textbf{einigen Dutzend GB/s}, PCIe 5.0 x16 bei \textbf{bis zu} \textbf{64 GB/s} (theoretisch).
  \item Der Speicher \textbf{auf der GPU} (VRAM/HBM) ist dagegen in einer ganz anderen Liga:
        Datacenter-GPUs erreichen \textbf{bis über 2 TB/s} Speicherbandbreite.
\end{itemize}
\end{block}

\begin{block}{Praktische Konsequenz (Merksatz)}
\textbf{Wenn Daten jeden Frame / jeden Iterationsschritt über PCIe nachgeladen werden müssen,}
dann bestimmt oft \textbf{der Transfer} die Gesamtgeschwindigkeit.
Deshalb: \textbf{Daten einmal auf die GPU laden und dort möglichst viel damit machen.}
\end{block}

\scriptsize
\href{https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-nvidia-us-2188504-web.pdf}{Quelle: NVIDIA A100 Datasheet (GPU Memory Bandwidth $>$ 2 TB/s)}\\
\href{https://www.computerbase.de/news/mainboards/pci-express-5-0-spezifikation-release.67965/}{Quelle: ComputerBase (PCIe 5.0 x16 $\sim$ 64 GB/s, dual-simplex erklärt)}
\end{frame}




\begin{frame}
    \frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}

\includegraphics[scale=0.15]{images/Shaderday_Intro/Shaderday_Intro_007}

\end{frame}


\begin{frame}
    \frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}

\includegraphics[scale=0.15]{images/Shaderday_Intro/Shaderday_Intro_001} 
\end{frame}



  
\begin{frame}
    \frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}
\begin{center}
\includegraphics[scale=0.26]{images/cgpipeline_grob}
\\
\includegraphics[scale=0.20]{images/Zeichnung_Shaderpipeline}

\end{center}
\end{frame}

\begin{frame}
    \frametitle{Computergrafik}
\framesubtitle{Einführung in GPU Computing}

  \begin{block}{}
\href{https://www.shadertoy.com/}{https://www.shadertoy.com/}
\end{block}
\end{frame}

\end{document}
